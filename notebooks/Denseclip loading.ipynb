{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8b4c78d-eddc-435b-b0df-f0e1fe4e78b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7408f917-43da-4474-b7a6-b8f1e6d839c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"../denseclip_configs/denseclip_fpn_res50_512x512_80k.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8270c05-ace6-4985-b240-eefa86a4a5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maverick/Projects/ml-scratchpad/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please install Colossal-AI from https://www.colossalai.org/download or from source\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maverick/Projects/ml-scratchpad/notebooks/../colossalai/pipeline/schedule/_utils.py:19: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _register_pytree_node(OrderedDict, _odict_flatten, _odict_unflatten)\n",
      "/home/maverick/Projects/ml-scratchpad/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py:300: UserWarning: <class 'collections.OrderedDict'> is already registered as pytree node. Overwriting the previous registration.\n",
      "  warnings.warn(\n",
      "/home/maverick/Projects/ml-scratchpad/notebooks/../colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
      "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n"
     ]
    }
   ],
   "source": [
    "from mmengine.config import Config\n",
    "from mmseg.models import build_segmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c172dd7-a774-4949-9381-0a7334ad6041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.models.components.denseclip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d13def6-8710-41e5-9e58-28ed2a8eca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile(cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45f1e5a2-770f-4bcd-8453-22f02ce39a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: ../denseclip_configs/denseclip_fpn_res50_512x512_80k.py): {'norm_cfg': {'type': 'SyncBN', 'requires_grad': True}, 'model': {'type': 'DenseCLIP', 'pretrained': 'pretrained/RN50.pt', 'context_length': 5, 'backbone': {'type': 'CLIPResNetWithAttention', 'layers': [3, 4, 6, 3], 'style': 'pytorch', 'output_dim': 1024, 'input_resolution': 512}, 'text_encoder': {'type': 'CLIPTextContextEncoder', 'context_length': 13, 'style': 'pytorch', 'embed_dim': 1024, 'transformer_width': 512, 'transformer_heads': 8, 'transformer_layers': 12}, 'context_decoder': {'type': 'ContextDecoder', 'context_length': 16, 'transformer_width': 256, 'transformer_heads': 4, 'transformer_layers': 3, 'visual_dim': 1024, 'dropout': 0.1, 'outdim': 1024, 'style': 'pytorch'}, 'neck': {'type': 'FPN', 'in_channels': [256, 512, 1024, 2198], 'out_channels': 256, 'num_outs': 4}, 'decode_head': {'type': 'FPNHead', 'in_channels': [256, 256, 256, 256], 'in_index': [0, 1, 2, 3], 'feature_strides': [4, 8, 16, 32], 'channels': 256, 'dropout_ratio': 0.1, 'num_classes': 150, 'norm_cfg': {'type': 'SyncBN', 'requires_grad': True}, 'align_corners': False, 'loss_decode': {'type': 'CrossEntropyLoss', 'use_sigmoid': False, 'loss_weight': 1.0}}, 'identity_head': {'type': 'IdentityHead', 'in_channels': 1, 'channels': 1, 'num_classes': 1, 'dropout_ratio': 0.1, 'align_corners': False, 'loss_decode': {'type': 'CrossEntropyLoss', 'use_sigmoid': False, 'loss_weight': 0.4}}, 'train_cfg': {}, 'test_cfg': {'mode': 'slide', 'crop_size': (512, 512), 'stride': (341, 341)}, 'text_head': False}, 'dataset_type': 'ADE20KDataset', 'data_root': 'data/ade/ADEChallengeData2016', 'IMG_MEAN': [122.7709383, 116.7460125, 104.09373615000001], 'IMG_VAR': [68.5005327, 66.6321579, 70.32316304999999], 'img_norm_cfg': {'mean': [122.7709383, 116.7460125, 104.09373615000001], 'std': [68.5005327, 66.6321579, 70.32316304999999], 'to_rgb': True}, 'crop_size': (512, 512), 'train_pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'reduce_zero_label': True}, {'type': 'Resize', 'img_scale': (2048, 512), 'ratio_range': (0.5, 2.0)}, {'type': 'RandomCrop', 'crop_size': (512, 512), 'cat_max_ratio': 0.75}, {'type': 'RandomFlip', 'prob': 0.5}, {'type': 'PhotoMetricDistortion'}, {'type': 'Normalize', 'mean': [122.7709383, 116.7460125, 104.09373615000001], 'std': [68.5005327, 66.6321579, 70.32316304999999], 'to_rgb': True}, {'type': 'Pad', 'size': (512, 512), 'pad_val': 0, 'seg_pad_val': 255}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_semantic_seg']}], 'test_pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (2048, 512), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [122.7709383, 116.7460125, 104.09373615000001], 'std': [68.5005327, 66.6321579, 70.32316304999999], 'to_rgb': True}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}], 'data': {'samples_per_gpu': 4, 'workers_per_gpu': 4, 'train': {'type': 'ADE20KDataset', 'data_root': 'data/ade/ADEChallengeData2016', 'img_dir': 'images/training', 'ann_dir': 'annotations/training', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'reduce_zero_label': True}, {'type': 'Resize', 'img_scale': (2048, 512), 'ratio_range': (0.5, 2.0)}, {'type': 'RandomCrop', 'crop_size': (512, 512), 'cat_max_ratio': 0.75}, {'type': 'RandomFlip', 'prob': 0.5}, {'type': 'PhotoMetricDistortion'}, {'type': 'Normalize', 'mean': [122.7709383, 116.7460125, 104.09373615000001], 'std': [68.5005327, 66.6321579, 70.32316304999999], 'to_rgb': True}, {'type': 'Pad', 'size': (512, 512), 'pad_val': 0, 'seg_pad_val': 255}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_semantic_seg']}]}, 'val': {'type': 'ADE20KDataset', 'data_root': 'data/ade/ADEChallengeData2016', 'img_dir': 'images/validation', 'ann_dir': 'annotations/validation', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (2048, 512), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [122.7709383, 116.7460125, 104.09373615000001], 'std': [68.5005327, 66.6321579, 70.32316304999999], 'to_rgb': True}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}]}, 'test': {'type': 'ADE20KDataset', 'data_root': 'data/ade/ADEChallengeData2016', 'img_dir': 'images/validation', 'ann_dir': 'annotations/validation', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (2048, 512), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [122.7709383, 116.7460125, 104.09373615000001], 'std': [68.5005327, 66.6321579, 70.32316304999999], 'to_rgb': True}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}]}}, 'log_config': {'interval': 50, 'hooks': [{'type': 'TextLoggerHook', 'by_epoch': False}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'cudnn_benchmark': True, 'find_unused_parameters': True, 'optimizer': {'type': 'AdamW', 'lr': 0.0001, 'weight_decay': 0.0001, 'paramwise_cfg': {'custom_keys': {'backbone': {'lr_mult': 0.1}, 'text_encoder': {'lr_mult': 0.0}, 'norm': {'decay_mult': 0.0}}}}, 'optimizer_config': {}, 'lr_config': {'policy': 'poly', 'power': 0.9, 'min_lr': 1e-06, 'by_epoch': False, 'warmup': 'linear', 'warmup_iters': 1500, 'warmup_ratio': 1e-06}, 'runner': {'type': 'IterBasedRunner', 'max_iters': 80000}, 'checkpoint_config': {'by_epoch': False, 'interval': 8000}, 'evaluation': {'interval': 8000, 'metric': 'mIoU'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e61f2042-6084-418d-8e30-fd014506b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model.pretrained = None\n",
    "cfg.data.test.test_mode = True\n",
    "cfg.model.train_cfg = None\n",
    "cfg.model.class_names = ['wall', 'building', 'sky', 'floor', 'tree', 'ceiling', 'road',\n",
    "                 'bed ', 'windowpane', 'grass', 'cabinet', 'sidewalk',\n",
    "                 'person', 'earth', 'door', 'table', 'mountain', 'plant',\n",
    "                 'curtain', 'chair', 'car', 'water', 'painting', 'sofa',\n",
    "                 'shelf', 'house', 'sea', 'mirror', 'rug', 'field', 'armchair',\n",
    "                 'seat', 'fence', 'desk', 'rock', 'wardrobe', 'lamp',\n",
    "                 'bathtub', 'railing', 'cushion', 'base', 'box', 'column',\n",
    "                 'signboard', 'chest of drawers', 'counter', 'sand', 'sink',\n",
    "                 'skyscraper', 'fireplace', 'refrigerator', 'grandstand',\n",
    "                 'path', 'stairs', 'runway', 'case', 'pool table', 'pillow',\n",
    "                 'screen door', 'stairway', 'river', 'bridge', 'bookcase',\n",
    "                 'blind', 'coffee table', 'toilet', 'flower', 'book', 'hill',\n",
    "                 'bench', 'countertop', 'stove', 'palm', 'kitchen island',\n",
    "                 'computer', 'swivel chair', 'boat', 'bar', 'arcade machine',\n",
    "                 'hovel', 'bus', 'towel', 'light', 'truck', 'tower',\n",
    "                 'chandelier', 'awning', 'streetlight', 'booth',\n",
    "                 'television receiver', 'airplane', 'dirt track', 'apparel',\n",
    "                 'pole', 'land', 'bannister', 'escalator', 'ottoman', 'bottle',\n",
    "                 'buffet', 'poster', 'stage', 'van', 'ship', 'fountain',\n",
    "                 'conveyer belt', 'canopy', 'washer', 'plaything',\n",
    "                 'swimming pool', 'stool', 'barrel', 'basket', 'waterfall',\n",
    "                 'tent', 'bag', 'minibike', 'cradle', 'oven', 'ball', 'food',\n",
    "                 'step', 'tank', 'trade name', 'microwave', 'pot', 'animal',\n",
    "                 'bicycle', 'lake', 'dishwasher', 'screen', 'blanket',\n",
    "                 'sculpture', 'hood', 'sconce', 'vase', 'traffic light',\n",
    "                 'tray', 'ashcan', 'fan', 'pier', 'crt screen', 'plate',\n",
    "                 'monitor', 'bulletin board', 'shower', 'radiator', 'glass',\n",
    "                 'clock', 'flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2694b4da-06c4-4791-a7e9-dd8b7df4e80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'DenseCLIP',\n",
       " 'pretrained': None,\n",
       " 'context_length': 5,\n",
       " 'backbone': {'type': 'CLIPResNetWithAttention',\n",
       "  'layers': [3, 4, 6, 3],\n",
       "  'style': 'pytorch',\n",
       "  'output_dim': 1024,\n",
       "  'input_resolution': 512},\n",
       " 'text_encoder': {'type': 'CLIPTextContextEncoder',\n",
       "  'context_length': 13,\n",
       "  'style': 'pytorch',\n",
       "  'embed_dim': 1024,\n",
       "  'transformer_width': 512,\n",
       "  'transformer_heads': 8,\n",
       "  'transformer_layers': 12},\n",
       " 'context_decoder': {'type': 'ContextDecoder',\n",
       "  'context_length': 16,\n",
       "  'transformer_width': 256,\n",
       "  'transformer_heads': 4,\n",
       "  'transformer_layers': 3,\n",
       "  'visual_dim': 1024,\n",
       "  'dropout': 0.1,\n",
       "  'outdim': 1024,\n",
       "  'style': 'pytorch'},\n",
       " 'neck': {'type': 'FPN',\n",
       "  'in_channels': [256, 512, 1024, 2198],\n",
       "  'out_channels': 256,\n",
       "  'num_outs': 4},\n",
       " 'decode_head': {'type': 'FPNHead',\n",
       "  'in_channels': [256, 256, 256, 256],\n",
       "  'in_index': [0, 1, 2, 3],\n",
       "  'feature_strides': [4, 8, 16, 32],\n",
       "  'channels': 256,\n",
       "  'dropout_ratio': 0.1,\n",
       "  'num_classes': 150,\n",
       "  'norm_cfg': {'type': 'SyncBN', 'requires_grad': True},\n",
       "  'align_corners': False,\n",
       "  'loss_decode': {'type': 'CrossEntropyLoss',\n",
       "   'use_sigmoid': False,\n",
       "   'loss_weight': 1.0}},\n",
       " 'identity_head': {'type': 'IdentityHead',\n",
       "  'in_channels': 1,\n",
       "  'channels': 1,\n",
       "  'num_classes': 1,\n",
       "  'dropout_ratio': 0.1,\n",
       "  'align_corners': False,\n",
       "  'loss_decode': {'type': 'CrossEntropyLoss',\n",
       "   'use_sigmoid': False,\n",
       "   'loss_weight': 0.4}},\n",
       " 'train_cfg': None,\n",
       " 'test_cfg': {'mode': 'slide', 'crop_size': (512, 512), 'stride': (341, 341)},\n",
       " 'text_head': False,\n",
       " 'class_names': ['wall',\n",
       "  'building',\n",
       "  'sky',\n",
       "  'floor',\n",
       "  'tree',\n",
       "  'ceiling',\n",
       "  'road',\n",
       "  'bed ',\n",
       "  'windowpane',\n",
       "  'grass',\n",
       "  'cabinet',\n",
       "  'sidewalk',\n",
       "  'person',\n",
       "  'earth',\n",
       "  'door',\n",
       "  'table',\n",
       "  'mountain',\n",
       "  'plant',\n",
       "  'curtain',\n",
       "  'chair',\n",
       "  'car',\n",
       "  'water',\n",
       "  'painting',\n",
       "  'sofa',\n",
       "  'shelf',\n",
       "  'house',\n",
       "  'sea',\n",
       "  'mirror',\n",
       "  'rug',\n",
       "  'field',\n",
       "  'armchair',\n",
       "  'seat',\n",
       "  'fence',\n",
       "  'desk',\n",
       "  'rock',\n",
       "  'wardrobe',\n",
       "  'lamp',\n",
       "  'bathtub',\n",
       "  'railing',\n",
       "  'cushion',\n",
       "  'base',\n",
       "  'box',\n",
       "  'column',\n",
       "  'signboard',\n",
       "  'chest of drawers',\n",
       "  'counter',\n",
       "  'sand',\n",
       "  'sink',\n",
       "  'skyscraper',\n",
       "  'fireplace',\n",
       "  'refrigerator',\n",
       "  'grandstand',\n",
       "  'path',\n",
       "  'stairs',\n",
       "  'runway',\n",
       "  'case',\n",
       "  'pool table',\n",
       "  'pillow',\n",
       "  'screen door',\n",
       "  'stairway',\n",
       "  'river',\n",
       "  'bridge',\n",
       "  'bookcase',\n",
       "  'blind',\n",
       "  'coffee table',\n",
       "  'toilet',\n",
       "  'flower',\n",
       "  'book',\n",
       "  'hill',\n",
       "  'bench',\n",
       "  'countertop',\n",
       "  'stove',\n",
       "  'palm',\n",
       "  'kitchen island',\n",
       "  'computer',\n",
       "  'swivel chair',\n",
       "  'boat',\n",
       "  'bar',\n",
       "  'arcade machine',\n",
       "  'hovel',\n",
       "  'bus',\n",
       "  'towel',\n",
       "  'light',\n",
       "  'truck',\n",
       "  'tower',\n",
       "  'chandelier',\n",
       "  'awning',\n",
       "  'streetlight',\n",
       "  'booth',\n",
       "  'television receiver',\n",
       "  'airplane',\n",
       "  'dirt track',\n",
       "  'apparel',\n",
       "  'pole',\n",
       "  'land',\n",
       "  'bannister',\n",
       "  'escalator',\n",
       "  'ottoman',\n",
       "  'bottle',\n",
       "  'buffet',\n",
       "  'poster',\n",
       "  'stage',\n",
       "  'van',\n",
       "  'ship',\n",
       "  'fountain',\n",
       "  'conveyer belt',\n",
       "  'canopy',\n",
       "  'washer',\n",
       "  'plaything',\n",
       "  'swimming pool',\n",
       "  'stool',\n",
       "  'barrel',\n",
       "  'basket',\n",
       "  'waterfall',\n",
       "  'tent',\n",
       "  'bag',\n",
       "  'minibike',\n",
       "  'cradle',\n",
       "  'oven',\n",
       "  'ball',\n",
       "  'food',\n",
       "  'step',\n",
       "  'tank',\n",
       "  'trade name',\n",
       "  'microwave',\n",
       "  'pot',\n",
       "  'animal',\n",
       "  'bicycle',\n",
       "  'lake',\n",
       "  'dishwasher',\n",
       "  'screen',\n",
       "  'blanket',\n",
       "  'sculpture',\n",
       "  'hood',\n",
       "  'sconce',\n",
       "  'vase',\n",
       "  'traffic light',\n",
       "  'tray',\n",
       "  'ashcan',\n",
       "  'fan',\n",
       "  'pier',\n",
       "  'crt screen',\n",
       "  'plate',\n",
       "  'monitor',\n",
       "  'bulletin board',\n",
       "  'shower',\n",
       "  'radiator',\n",
       "  'glass',\n",
       "  'clock',\n",
       "  'flag']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adda74f9-1211-4f0b-acbb-9e51494a12ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maverick/Projects/ml-scratchpad/notebooks/../mmseg/models/builder.py:15: UserWarning: ``build_backbone`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn(\n",
      "/home/maverick/Projects/ml-scratchpad/notebooks/../mmseg/models/builder.py:24: UserWarning: ``build_neck`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn(\n",
      "/home/maverick/Projects/ml-scratchpad/notebooks/../mmseg/models/builder.py:33: UserWarning: ``build_head`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn(\n",
      "/home/maverick/Projects/ml-scratchpad/notebooks/../mmseg/models/builder.py:42: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn(\n",
      "/home/maverick/Projects/ml-scratchpad/notebooks/../mmseg/models/losses/cross_entropy_loss.py:254: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n",
      "/home/maverick/Projects/ml-scratchpad/notebooks/../mmseg/models/decode_heads/decode_head.py:147: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.3\")\n"
     ]
    }
   ],
   "source": [
    "model = build_segmentor(cfg.model, test_cfg=cfg.get('test_cfg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34939b7e-8ac4-440c-92e0-0460f08d9069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseCLIP(\n",
       "  (data_preprocessor): BaseDataPreprocessor()\n",
       "  (backbone): CLIPResNetWithAttention(\n",
       "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (attnpool): AttentionPool2d(\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (text_encoder): CLIPTextContextEncoder(\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (token_embedding): Embedding(49408, 512)\n",
       "    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (context_decoder): ContextDecoder(\n",
       "    (memory_proj): Sequential(\n",
       "      (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_proj): Sequential(\n",
       "      (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    )\n",
       "    (decoder): ModuleList(\n",
       "      (0-2): 3 x TransformerDecoderLayer(\n",
       "        (self_attn): Attention(\n",
       "          (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (cross_attn): Attention(\n",
       "          (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out_proj): Sequential(\n",
       "      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (neck): FPN(\n",
       "    (lateral_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (3): ConvModule(\n",
       "        (conv): Conv2d(2198, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (fpn_convs): ModuleList(\n",
       "      (0-3): 4 x ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
       "  (decode_head): FPNHead(\n",
       "    input_transform=multiple_select, ignore_index=255, align_corners=False\n",
       "    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n",
       "    (conv_seg): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (scale_heads): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Upsample()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Upsample()\n",
       "        (2): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Upsample()\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Upsample()\n",
       "        (2): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Upsample()\n",
       "        (4): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Upsample()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
       "  (identity_head): IdentityHead(\n",
       "    input_transform=None, ignore_index=255, align_corners=False\n",
       "    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n",
       "    (conv_seg): None\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "  )\n",
       "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf68c412-71fd-4a9b-a2f2-4b852de3c433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  512,  2571,   513,     0,     0],\n",
       "        [  512,  2309,   513,     0,     0],\n",
       "        [  512,  2392,   513,     0,     0],\n",
       "        [  512,  4127,   513,     0,     0],\n",
       "        [  512,  2679,   513,     0,     0],\n",
       "        [  512, 12376,   513,     0,     0],\n",
       "        [  512,  1761,   513,     0,     0],\n",
       "        [  512,  2724,   513,     0,     0],\n",
       "        [  512, 26677, 27472,   513,     0],\n",
       "        [  512,  5924,   513,     0,     0],\n",
       "        [  512,  9939,   513,     0,     0],\n",
       "        [  512, 23280,   513,     0,     0],\n",
       "        [  512,  2535,   513,     0,     0],\n",
       "        [  512,  3477,   513,     0,     0],\n",
       "        [  512,  2491,   513,     0,     0],\n",
       "        [  512,  2177,   513,     0,     0],\n",
       "        [  512,  3967,   513,     0,     0],\n",
       "        [  512,  3914,   513,     0,     0],\n",
       "        [  512, 17225,   513,     0,     0],\n",
       "        [  512,  4271,   513,     0,     0],\n",
       "        [  512,  1617,   513,     0,     0],\n",
       "        [  512,  1575,   513,     0,     0],\n",
       "        [  512,  3088,   513,     0,     0],\n",
       "        [  512, 15725,   513,     0,     0],\n",
       "        [  512, 10957,   513,     0,     0],\n",
       "        [  512,  1214,   513,     0,     0],\n",
       "        [  512,  2104,   513,     0,     0],\n",
       "        [  512,  7222,   513,     0,     0],\n",
       "        [  512, 19222,   513,     0,     0],\n",
       "        [  512,  1572,   513,     0,     0],\n",
       "        [  512, 45759,   513,     0,     0],\n",
       "        [  512,  4924,   513,     0,     0],\n",
       "        [  512, 12681,   513,     0,     0],\n",
       "        [  512,  6552,   513,     0,     0],\n",
       "        [  512,  2174,   513,     0,     0],\n",
       "        [  512, 15022,   513,     0,     0],\n",
       "        [  512, 10727,   513,     0,     0],\n",
       "        [  512, 39944,   513,     0,     0],\n",
       "        [  512,   561,  3301,   513,     0],\n",
       "        [  512, 20855,   513,     0,     0],\n",
       "        [  512,  4581,   513,     0,     0],\n",
       "        [  512,  2065,   513,     0,     0],\n",
       "        [  512, 10595,   513,     0,     0],\n",
       "        [  512,  5540,  1974,   513,     0],\n",
       "        [  512, 10565,   541, 38977,   513],\n",
       "        [  512,  7354,   513,     0,     0],\n",
       "        [  512,  5096,   513,     0,     0],\n",
       "        [  512, 14553,   513,     0,     0],\n",
       "        [  512,  3077, 11189,  1286,   513],\n",
       "        [  512, 23052,   513,     0,     0],\n",
       "        [  512, 36664,   513,     0,     0],\n",
       "        [  512, 43174,   513,     0,     0],\n",
       "        [  512,  5037,   513,     0,     0],\n",
       "        [  512,  9579,   513,     0,     0],\n",
       "        [  512, 13929,   513,     0,     0],\n",
       "        [  512,  2070,   513,     0,     0],\n",
       "        [  512,  2833,  2177,   513,     0],\n",
       "        [  512, 12184,   513,     0,     0],\n",
       "        [  512,  3752,  2491,   513,     0],\n",
       "        [  512, 45561,   513,     0,     0],\n",
       "        [  512,  2475,   513,     0,     0],\n",
       "        [  512,  2467,   513,     0,     0],\n",
       "        [  512,  2830,  2070,   513,     0],\n",
       "        [  512,  8353,   513,     0,     0],\n",
       "        [  512,  2455,  2177,   513,     0],\n",
       "        [  512, 11073,   513,     0,     0],\n",
       "        [  512,  4057,   513,     0,     0],\n",
       "        [  512,  1118,   513,     0,     0],\n",
       "        [  512,  2684,   513,     0,     0],\n",
       "        [  512,  8773,   513,     0,     0],\n",
       "        [  512, 10136,  1255,   513,     0],\n",
       "        [  512, 21425,   513,     0,     0],\n",
       "        [  512,  8614,   513,     0,     0],\n",
       "        [  512,  4487,  2621,   513,     0],\n",
       "        [  512, 11641,   654,   513,     0],\n",
       "        [  512, 48258,  4271,   513,     0],\n",
       "        [  512,  4442,   513,     0,     0],\n",
       "        [  512,  2413,   513,     0,     0],\n",
       "        [  512, 13333,  4171,   513,     0],\n",
       "        [  512,   608,  1289,   513,     0],\n",
       "        [  512,  2842,   513,     0,     0],\n",
       "        [  512, 15955,   513,     0,     0],\n",
       "        [  512,  1397,   513,     0,     0],\n",
       "        [  512,  4631,   513,     0,     0],\n",
       "        [  512,  4732,   513,     0,     0],\n",
       "        [  512, 30572,   513,     0,     0],\n",
       "        [  512,   810,   764,   513,     0],\n",
       "        [  512,  4841,  1397,   513,     0],\n",
       "        [  512,  3973,   513,     0,     0],\n",
       "        [  512,  8610, 17661,   513,     0],\n",
       "        [  512, 16453,   513,     0,     0],\n",
       "        [  512, 11797,  2702,   513,     0],\n",
       "        [  512, 13974,   513,     0,     0],\n",
       "        [  512,  8172,   513,     0,     0],\n",
       "        [  512,   975,   513,     0,     0],\n",
       "        [  512,  1161, 36642,   513,     0],\n",
       "        [  512, 15904,  1964,   513,     0],\n",
       "        [  512, 27505,   513,     0,     0],\n",
       "        [  512,  5394,   513,     0,     0],\n",
       "        [  512, 17831,   513,     0,     0],\n",
       "        [  512,  3576,   513,     0,     0],\n",
       "        [  512,  2172,   513,     0,     0],\n",
       "        [  512,  2453,   513,     0,     0],\n",
       "        [  512,  1160,   513,     0,     0],\n",
       "        [  512, 13407,   513,     0,     0],\n",
       "        [  512, 18423,  2373,  7375,   513],\n",
       "        [  512, 26063,   513,     0,     0],\n",
       "        [  512, 24087,   513,     0,     0],\n",
       "        [  512,  1224,   948,   513,     0],\n",
       "        [  512,  7413,  2833,   513,     0],\n",
       "        [  512, 22316,   513,     0,     0],\n",
       "        [  512, 11705,   513,     0,     0],\n",
       "        [  512, 10340,   513,     0,     0],\n",
       "        [  512, 16405,   513,     0,     0],\n",
       "        [  512, 10784,   513,     0,     0],\n",
       "        [  512,  3367,   513,     0,     0],\n",
       "        [  512,  1812,  3703,   513,     0],\n",
       "        [  512, 29386,   513,     0,     0],\n",
       "        [  512, 12581,   513,     0,     0],\n",
       "        [  512,  1071,   513,     0,     0],\n",
       "        [  512,  1561,   513,     0,     0],\n",
       "        [  512,  3350,   513,     0,     0],\n",
       "        [  512,  6174,   513,     0,     0],\n",
       "        [  512,  3631,  1983,   513,     0],\n",
       "        [  512, 24242,   513,     0,     0],\n",
       "        [  512,  5170,   513,     0,     0],\n",
       "        [  512,  4670,   513,     0,     0],\n",
       "        [  512, 11654,   513,     0,     0],\n",
       "        [  512,  2555,   513,     0,     0],\n",
       "        [  512, 40526,   513,     0,     0],\n",
       "        [  512,  3752,   513,     0,     0],\n",
       "        [  512, 12880,   513,     0,     0],\n",
       "        [  512,  8759,   513,     0,     0],\n",
       "        [  512,  3224,   513,     0,     0],\n",
       "        [  512, 17165,   631,   513,     0],\n",
       "        [  512, 20433,   513,     0,     0],\n",
       "        [  512,  3401,  1397,   513,     0],\n",
       "        [  512, 14623,   513,     0,     0],\n",
       "        [  512,  2069,   755,   513,     0],\n",
       "        [  512,  2263,   513,     0,     0],\n",
       "        [  512, 11350,   513,     0,     0],\n",
       "        [  512, 43879,  3752,   513,     0],\n",
       "        [  512,  5137,   513,     0,     0],\n",
       "        [  512, 10200,   513,     0,     0],\n",
       "        [  512, 19640,  1974,   513,     0],\n",
       "        [  512,  7779,   513,     0,     0],\n",
       "        [  512, 39374,   513,     0,     0],\n",
       "        [  512,  3315,   513,     0,     0],\n",
       "        [  512,  6718,   513,     0,     0],\n",
       "        [  512,  4861,   513,     0,     0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19565fdf-d1e0-4cce-bff3-67785d3a22ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
