# @package _global_

defaults:
  - _self_
  - data: mnist # choose datamodule with `test_dataloader()` for evaluation
  - model: mnist
  - logger: null
  - trainer: default
  - paths: default
  - extras: default
  - hydra: default

task_name: "eval"

tags: ["dev"]

testing: true

# predict on test set, using best model weights achieved during training
# lightning chooses best weights based on the metric specified in checkpoint callback
predict: true

# passing checkpoint path is necessary for evaluation
ckpt_path: ???

model_pretrained_path: openai/clip-vit-base-patch16
tokenizer_pretrained_path: ${model_pretrained_path}
image_pretrained_path: ${model_pretrained_path}
text_pretrained_path: ${model_pretrained_path}

exp_name: "img_${img_size}_b${data.batch_size}_lr${model.optimizer.lr}_p${trainer.precision}"
output_masks_dir: "output_masks/phrasecut/${exp_name}"

img_size: 224
data_root: ${oc.env:PHRASECUT_ROOT}

img_mean: [0.48145466, 0.4578275, 0.40821073]
img_std: [0.26862954, 0.26130258, 0.27577711]

# Image pre-processing configs
train_transforms:
  _target_: albumentations.Compose
  transforms:
    - _target_: albumentations.SmallestMaxSize
      max_size: ${img_size}
    - _target_: albumentations.Rotate
      limit: 10
      border_mode: ${import_eval:cv2.BORDER_REPLICATE}
      p: 0.2
    - _target_: albumentations.RandomCrop
      width: ${img_size}
      height: ${img_size}
    - _target_: albumentations.RandomBrightnessContrast
      contrast_limit: 0.1
      brightness_limit: 0.1
      brightness_by_max: false
      p: 0.2
    - _target_: albumentations.Normalize
      mean: ${img_mean}
      std: ${img_std}
    - _target_: albumentations.pytorch.ToTensorV2
      transpose_mask: true

_eval_transforms: 
  _target_: albumentations.Compose
  transforms:
    - _target_: albumentations.Resize
      height: ${img_size}
      width: ${img_size}
    - _target_: albumentations.Normalize
      mean: ${img_mean}
      std: ${img_std}
    - _target_: albumentations.pytorch.ToTensorV2
      transpose_mask: true

val_transforms: ${_eval_transforms}
test_transforms: ${_eval_transforms}
