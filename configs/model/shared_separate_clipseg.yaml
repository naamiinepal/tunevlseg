_target_: src.models.image_text_mask_module.ImageTextMaskModule

net:
  _target_: src.models.core_models.coop.SharedSeparateCLIPSeg
  model_cfg:
    pretrained_model_name_or_path: ${model_pretrained_path}
    freeze_encoder: false
    freeze_decoder: false
  context_learner:
    _target_: src.models.core_models.coop.context_learner.SharedSeparateLearner
    _partial_: true
    shared_dim: 64
    prompt_depth: 1
    use_unified_projection: false
    intermediate_dim: null
    use_proj_norm: true
    use_lora_proj: false
    num_context: 4
    vector_std: 1.02
  freeze_all: true
  no_freeze_last_layer: false
  use_new_last_layer: true
  new_last_layer_kernel_size: 5
  residual_ratio: 0.5

loss_fn:
  _target_: monai.losses.DiceCELoss
  sigmoid: true
  lambda_dice: 1
  lambda_ce: 0.2

weight_decay: 0.0
optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 2.0e-4

# lr_scheduler_config:
#   interval: step
#
# scheduler:
#   _target_: torch.optim.lr_scheduler.CosineAnnealingLR
#   _partial_: true
#   T_max: 2.0e6
#   eta_min: 1.0e-6

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.2
  patience: 5

# compile model for faster training with pytorch 2.0
compile: false

task: binary
threshold: 0.5
